{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456de0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization import encode, decode, vocab_size, vocab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d1f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b84d7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(81, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=EMBEDDING_DIM)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3c0889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0199,  0.4202, -1.0543,  ...,  0.0318,  0.5748,  0.3618],\n",
       "        [-0.6898,  3.3488,  2.5956,  ..., -0.0289,  1.3268, -0.2817],\n",
       "        [-0.2539, -0.8296, -0.1288,  ..., -1.1616, -0.9264,  0.3339],\n",
       "        ...,\n",
       "        [ 0.3923, -1.4268,  2.0271,  ..., -0.8077,  0.0035,  0.8254],\n",
       "        [ 0.0321, -1.0122,  0.7443,  ...,  0.1071,  1.8215,  0.6387],\n",
       "        [-0.3394,  0.9999,  0.2835,  ..., -0.9982,  0.2616,  0.2585]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759e2c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [4, 0, 67, 23, 30, 29, 27, 67, 23, 27, 76, 25, 61, 48, 27, 53, 67, 23, 25, 34]\n",
      "input_ids: tensor([ 4,  0, 67, 23, 30, 29, 27, 67, 23, 27, 76, 25, 61, 48, 27, 53, 67, 23,\n",
      "        25, 34])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = encode(\"Bhisma is very wise.\")\n",
    "print(f\"input_ids: {input_ids}\")\n",
    "print(f\"input_ids: {torch.tensor(input_ids)}\")\n",
    "embeddings = embedding_layer(torch.tensor(input_ids))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc694f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6767,  0.9284,  1.1302, -1.2293, -0.2218, -0.5815,  1.1720, -0.1322,\n",
       "        -1.9772,  0.3813, -0.5317, -1.1737, -0.8880, -1.3582, -0.7713, -0.7702,\n",
       "        -0.5238,  0.6970,  0.0966,  0.4947, -0.6282,  1.2888,  0.9893,  0.0439,\n",
       "        -0.1704,  0.8909,  0.5912, -0.9379,  0.8538,  0.4885,  0.4097, -0.4588],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_of_B = embeddings[0]\n",
    "embedding_of_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e16a0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 100\n",
    "d_model = EMBEDDING_DIM\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2028b957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "position.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f7d88",
   "metadata": {},
   "source": [
    "$$\\frac{1}{10000^{2i/d_{model}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ceafe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20., 22., 24., 26.,\n",
       "        28., 30.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2).float() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a737bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28782313662425574"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-math.log(10000.0) / d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8028c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000, -0.5756, -1.1513, -1.7269, -2.3026, -2.8782, -3.4539, -4.0295,\n",
       "        -4.6052, -5.1808, -5.7565, -6.3321, -6.9078, -7.4834, -8.0590, -8.6347])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "694bf1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "div_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5a0d31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 5.6234e-01, 3.1623e-01, 1.7783e-01, 1.0000e-01, 5.6234e-02,\n",
       "        3.1623e-02, 1.7783e-02, 1.0000e-02, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
       "        1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f786069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 5.6234e-01, 3.1623e-01,  ..., 5.6234e-04, 3.1623e-04,\n",
      "         1.7783e-04],\n",
      "        [2.0000e+00, 1.1247e+00, 6.3246e-01,  ..., 1.1247e-03, 6.3246e-04,\n",
      "         3.5566e-04],\n",
      "        ...,\n",
      "        [9.7000e+01, 5.4547e+01, 3.0674e+01,  ..., 5.4547e-02, 3.0674e-02,\n",
      "         1.7249e-02],\n",
      "        [9.8000e+01, 5.5109e+01, 3.0990e+01,  ..., 5.5109e-02, 3.0990e-02,\n",
      "         1.7427e-02],\n",
      "        [9.9000e+01, 5.5672e+01, 3.1307e+01,  ..., 5.5672e-02, 3.1307e-02,\n",
      "         1.7605e-02]])\n"
     ]
    }
   ],
   "source": [
    "print(position*div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60004d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32])\n"
     ]
    }
   ],
   "source": [
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dd66137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32])\n"
     ]
    }
   ],
   "source": [
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39e9636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  5.3317e-01,  ...,  1.0000e+00,\n",
       "          1.7783e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.0213e-01,  ...,  1.0000e+00,\n",
       "          3.5566e-04,  1.0000e+00],\n",
       "        ...,\n",
       "        [ 3.7961e-01, -9.2515e-01, -9.0865e-01,  ...,  9.9953e-01,\n",
       "          1.7248e-02,  9.9985e-01],\n",
       "        [-5.7338e-01, -8.1929e-01, -9.9136e-01,  ...,  9.9952e-01,\n",
       "          1.7426e-02,  9.9985e-01],\n",
       "        [-9.9921e-01,  3.9821e-02, -7.6875e-01,  ...,  9.9951e-01,\n",
       "          1.7604e-02,  9.9985e-01]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "10, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92a6b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model: The dimension of the embeddings (32 in your case).\n",
    "            max_len: The maximum sequence length your model will handle.\n",
    "            dropout: Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Create a matrix of [max_len, d_model] representing the positional encodings\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # Create a vector of positions [0, 1, 2, ..., max_len-1]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Calculate the division term for the sine/cosine formulas\n",
    "        # div_term = 1 / (10000 ^ (2i / d_model))\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # Apply cosine to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Add a batch dimension: [1, max_len, d_model]\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # Register 'pe' as a buffer. \n",
    "        # This means it's part of the state_dict but is NOT a learnable parameter.\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Add the positional encoding to the input embeddings\n",
    "        # We slice self.pe to match the sequence length of x\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66452945",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=EMBEDDING_DIM)\n",
    "pos_encoder = PositionalEncoding(d_model=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970381b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c96c6cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: tensor([ 4,  0, 67, 23,  0, 30, 29, 27, 67, 23, 27, 76, 25, 61, 48, 27, 53, 67,\n",
      "        23, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Bhishma is very wise\"\n",
    "tokens = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(f\"tokens: {tokens}\")\n",
    "embeddings = embedding_layer(tokens)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2f9d010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bhishma is very wise'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8b8be231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.9629e-02, -2.3094e-02,  1.3975e+00,  3.7862e-01, -3.4076e-01,\n",
       "           1.4400e+00, -1.1908e+00,  7.8693e-01, -5.1956e-02,  3.8565e-01,\n",
       "           2.4341e-01,  4.2516e-02,  4.9360e-01, -8.1355e-02, -8.8898e-01,\n",
       "           1.6459e+00,  4.5596e-01,  9.0416e-02,  6.1574e-01,  1.4290e+00,\n",
       "          -3.0128e-01, -7.4445e-01,  4.8218e-01, -1.4849e+00,  5.5940e-01,\n",
       "          -1.2439e-01,  1.3801e-01,  4.8013e-01, -8.8110e-01, -1.9698e-01,\n",
       "           9.3190e-02, -7.7100e-01],\n",
       "         [-2.0770e-02,  9.9981e-01,  8.4547e-01, -1.2986e+00, -3.4438e-01,\n",
       "           1.6602e+00, -6.6720e-01,  1.6941e-01, -9.8163e-01,  2.8308e-01,\n",
       "          -1.0780e+00, -1.1606e-01,  1.7840e-01,  5.5293e-01,  1.8219e-01,\n",
       "           7.6230e-01, -9.9815e-01,  3.6888e-01,  1.7049e-01,  8.2004e-01,\n",
       "          -5.3396e-01, -3.7870e-01,  6.1093e-01, -1.3668e+00, -6.7983e-01,\n",
       "           8.0038e-01,  5.6062e-01,  6.7685e-01, -2.0585e-01, -1.1079e+00,\n",
       "          -1.2637e+00,  7.9468e-01],\n",
       "         [ 1.0372e+00,  5.4230e-01, -1.6109e-01, -7.1117e-02, -2.1924e-01,\n",
       "          -6.1311e-01, -1.5370e+00,  2.9590e-01,  1.2552e+00,  9.3801e-01,\n",
       "           3.4831e+00,  8.3900e-01,  6.5607e-01,  2.3424e+00, -2.5169e+00,\n",
       "           4.9464e-01, -7.9943e-02,  6.2230e-02,  1.0104e+00, -5.2972e-01,\n",
       "           1.1360e+00,  3.8709e-01,  1.1140e+00, -5.9747e-01,  5.8162e-02,\n",
       "           1.9215e+00,  1.0320e-01,  2.1673e+00, -9.3786e-01,  6.2459e-02,\n",
       "           6.6224e-01,  3.5153e-01],\n",
       "         [-1.2884e+00, -5.4220e-01,  4.8975e-02, -1.5991e+00,  1.0390e+00,\n",
       "           3.1534e-01, -7.7721e-01, -4.0024e-01,  1.3719e+00, -6.1061e-01,\n",
       "          -9.7610e-01, -4.0126e-01, -2.7068e-01, -1.2235e+00, -4.0536e-01,\n",
       "          -1.9494e-01,  5.3057e-01, -5.7537e-01,  9.8938e-01,  3.2362e-01,\n",
       "           1.2551e-01, -1.8141e+00, -1.0934e+00, -1.0051e+00, -1.2109e+00,\n",
       "          -1.7673e-01, -9.4396e-01, -1.4489e+00, -7.5010e-01, -1.0736e+00,\n",
       "           9.5358e-01,  7.7746e-01],\n",
       "         [-2.0770e-02,  9.9981e-01,  8.4547e-01, -1.2986e+00, -3.4438e-01,\n",
       "           1.6602e+00, -6.6720e-01,  1.6941e-01, -9.8163e-01,  2.8308e-01,\n",
       "          -1.0780e+00, -1.1606e-01,  1.7840e-01,  5.5293e-01,  1.8219e-01,\n",
       "           7.6230e-01, -9.9815e-01,  3.6888e-01,  1.7049e-01,  8.2004e-01,\n",
       "          -5.3396e-01, -3.7870e-01,  6.1093e-01, -1.3668e+00, -6.7983e-01,\n",
       "           8.0038e-01,  5.6062e-01,  6.7685e-01, -2.0585e-01, -1.1079e+00,\n",
       "          -1.2637e+00,  7.9468e-01],\n",
       "         [-3.8963e-01, -1.7613e-01, -1.0041e-01,  2.3978e-02, -7.0964e-01,\n",
       "           1.2398e-01, -1.5609e+00, -6.2924e-01,  1.7206e-01,  1.7759e+00,\n",
       "          -5.7465e-01,  3.3997e-01, -1.1942e-02, -5.3643e-01,  1.6644e-01,\n",
       "           3.2785e-01, -1.0167e+00, -4.7524e-01, -7.6880e-01,  9.9689e-01,\n",
       "           7.0351e-01,  3.0346e-01,  5.5129e-01, -1.5879e+00, -1.4435e+00,\n",
       "           8.3092e-01, -5.8754e-01,  2.7573e-01,  1.5760e-02, -1.3250e+00,\n",
       "           2.9068e-01, -1.3639e+00],\n",
       "         [-2.8222e-01,  4.3353e-01, -9.6525e-01, -2.5359e-01,  2.1183e-01,\n",
       "          -8.0122e-01, -8.3008e-01, -1.5860e+00,  8.8367e-01, -7.4882e-01,\n",
       "           3.0292e-03,  9.9119e-01, -3.6843e-01, -1.3322e-01,  1.7557e+00,\n",
       "           5.5156e-01, -5.5880e-01, -1.3053e+00,  5.5986e-02,  2.1719e+00,\n",
       "           1.1491e+00,  1.2753e-01, -1.3618e+00, -4.0922e-01, -3.1633e-01,\n",
       "           5.8022e-02,  1.7700e+00,  1.1318e-01, -1.7968e-01, -3.4094e-01,\n",
       "           2.3365e-01, -3.0452e+00],\n",
       "         [-1.4652e+00, -7.8320e-02, -5.0135e-01,  1.9328e+00,  2.4749e-01,\n",
       "           1.4647e+00, -8.6321e-01, -1.5502e-01,  7.5193e-01, -1.1767e+00,\n",
       "           8.9244e-01, -8.0869e-01,  3.8825e-01, -1.1875e-01, -1.1312e+00,\n",
       "           8.7110e-01, -1.4008e-01, -2.7833e-02,  2.5959e+00, -9.0283e-02,\n",
       "           2.4173e-02, -6.7132e-01, -1.3127e-01, -1.1532e-01,  4.6400e-01,\n",
       "          -7.9338e-01, -1.4088e+00, -6.2451e-01,  3.6319e-01, -8.5360e-01,\n",
       "          -5.5233e-02,  6.1376e-01],\n",
       "         [ 1.0372e+00,  5.4230e-01, -1.6109e-01, -7.1117e-02, -2.1924e-01,\n",
       "          -6.1311e-01, -1.5370e+00,  2.9590e-01,  1.2552e+00,  9.3801e-01,\n",
       "           3.4831e+00,  8.3900e-01,  6.5607e-01,  2.3424e+00, -2.5169e+00,\n",
       "           4.9464e-01, -7.9943e-02,  6.2230e-02,  1.0104e+00, -5.2972e-01,\n",
       "           1.1360e+00,  3.8709e-01,  1.1140e+00, -5.9747e-01,  5.8162e-02,\n",
       "           1.9215e+00,  1.0320e-01,  2.1673e+00, -9.3786e-01,  6.2459e-02,\n",
       "           6.6224e-01,  3.5153e-01],\n",
       "         [-1.2884e+00, -5.4220e-01,  4.8975e-02, -1.5991e+00,  1.0390e+00,\n",
       "           3.1534e-01, -7.7721e-01, -4.0024e-01,  1.3719e+00, -6.1061e-01,\n",
       "          -9.7610e-01, -4.0126e-01, -2.7068e-01, -1.2235e+00, -4.0536e-01,\n",
       "          -1.9494e-01,  5.3057e-01, -5.7537e-01,  9.8938e-01,  3.2362e-01,\n",
       "           1.2551e-01, -1.8141e+00, -1.0934e+00, -1.0051e+00, -1.2109e+00,\n",
       "          -1.7673e-01, -9.4396e-01, -1.4489e+00, -7.5010e-01, -1.0736e+00,\n",
       "           9.5358e-01,  7.7746e-01],\n",
       "         [-1.4652e+00, -7.8320e-02, -5.0135e-01,  1.9328e+00,  2.4749e-01,\n",
       "           1.4647e+00, -8.6321e-01, -1.5502e-01,  7.5193e-01, -1.1767e+00,\n",
       "           8.9244e-01, -8.0869e-01,  3.8825e-01, -1.1875e-01, -1.1312e+00,\n",
       "           8.7110e-01, -1.4008e-01, -2.7833e-02,  2.5959e+00, -9.0283e-02,\n",
       "           2.4173e-02, -6.7132e-01, -1.3127e-01, -1.1532e-01,  4.6400e-01,\n",
       "          -7.9338e-01, -1.4088e+00, -6.2451e-01,  3.6319e-01, -8.5360e-01,\n",
       "          -5.5233e-02,  6.1376e-01],\n",
       "         [ 8.9197e-01, -9.6806e-01,  6.2975e-01,  9.5053e-02, -1.2722e+00,\n",
       "           5.1400e-01, -2.8434e+00,  3.4107e-01,  8.9204e-01, -8.9958e-02,\n",
       "           1.2395e+00, -2.6544e-01, -1.7836e+00, -4.3425e-02,  6.5133e-01,\n",
       "           9.9499e-01, -2.6058e-01, -6.3242e-01, -6.6903e-01,  6.8714e-01,\n",
       "          -3.8070e-01, -6.4517e-01, -1.1961e-02,  5.6875e-01,  1.1375e-02,\n",
       "           1.8993e+00, -6.6804e-01,  2.2725e-01,  8.2936e-02, -1.0059e+00,\n",
       "          -1.5449e+00,  6.5268e-01],\n",
       "         [-3.8766e-01,  5.8734e-01, -1.7504e+00, -5.8200e-01,  1.4518e+00,\n",
       "          -2.0279e-01, -5.5114e-01,  1.2416e+00,  6.9454e-01, -3.5066e-01,\n",
       "          -1.2682e+00,  7.0547e-01,  3.9340e-01,  2.4819e-01, -1.4684e-01,\n",
       "          -2.0840e-01,  4.2463e-01, -7.2402e-01,  1.5354e+00, -9.6251e-01,\n",
       "           6.4449e-03,  1.1665e+00,  2.4699e-01,  1.0120e+00,  1.8748e+00,\n",
       "           1.1014e-01,  1.9012e-01,  2.5675e-01,  9.9808e-01,  5.0770e-01,\n",
       "           5.9082e-02,  4.9443e-01],\n",
       "         [ 4.5766e-01,  3.5407e-01,  2.7410e-01, -8.6989e-01, -7.3838e-01,\n",
       "          -9.8343e-01, -2.1929e-01,  4.7718e-01,  2.0685e-01,  4.5787e-02,\n",
       "           6.0621e-01, -5.8262e-01, -1.7533e-01, -1.2599e+00,  1.4824e+00,\n",
       "          -4.9344e-01,  4.5300e-01, -1.3452e+00,  4.7391e-02, -3.2406e-01,\n",
       "           7.8408e-01,  4.3030e-01,  4.3808e-01,  3.9975e-01, -8.5789e-01,\n",
       "          -7.8574e-01, -5.1385e-01, -1.0208e+00, -6.7806e-01,  8.6080e-01,\n",
       "           6.3915e-02, -1.8630e+00],\n",
       "         [ 4.5115e-01, -3.7761e-02, -1.9509e+00, -1.9182e+00,  3.5334e-01,\n",
       "          -9.5093e-01, -2.4075e-01,  6.2102e-01,  1.1886e+00, -3.2182e-01,\n",
       "           3.9758e-02, -9.2835e-01, -5.4348e-01, -9.7508e-01,  2.3387e-01,\n",
       "          -9.4979e-01, -1.2528e+00,  1.1691e+00,  1.8898e+00,  1.5890e+00,\n",
       "          -1.4562e+00,  7.1957e-01, -2.3605e+00, -4.2353e-01,  1.2362e+00,\n",
       "           8.4628e-01,  1.4048e-01,  3.2148e-01,  1.2303e+00, -9.3177e-01,\n",
       "           1.1255e+00,  2.1275e-01],\n",
       "         [-1.4652e+00, -7.8320e-02, -5.0135e-01,  1.9328e+00,  2.4749e-01,\n",
       "           1.4647e+00, -8.6321e-01, -1.5502e-01,  7.5193e-01, -1.1767e+00,\n",
       "           8.9244e-01, -8.0869e-01,  3.8825e-01, -1.1875e-01, -1.1312e+00,\n",
       "           8.7110e-01, -1.4008e-01, -2.7833e-02,  2.5959e+00, -9.0283e-02,\n",
       "           2.4173e-02, -6.7132e-01, -1.3127e-01, -1.1532e-01,  4.6400e-01,\n",
       "          -7.9338e-01, -1.4088e+00, -6.2451e-01,  3.6319e-01, -8.5360e-01,\n",
       "          -5.5233e-02,  6.1376e-01],\n",
       "         [-4.5111e-01, -9.8544e-01, -6.2507e-02, -6.3153e-01,  1.0548e-01,\n",
       "           2.6211e-01, -6.9988e-01,  4.2261e-01, -9.5965e-01,  1.2063e-01,\n",
       "           4.0767e-02,  4.6028e-01, -1.5335e+00,  5.2113e-01,  5.3150e-01,\n",
       "          -2.7412e+00, -7.2355e-01,  5.2563e-01,  7.3704e-01,  2.6649e-01,\n",
       "          -5.4886e-01,  7.8347e-01, -1.6359e-01,  1.6166e+00, -2.4673e-01,\n",
       "          -5.7170e-01, -6.3727e-01,  6.6036e-01, -8.0748e-01,  7.9102e-01,\n",
       "           6.6447e-01,  6.3841e-01],\n",
       "         [ 1.0372e+00,  5.4230e-01, -1.6109e-01, -7.1117e-02, -2.1924e-01,\n",
       "          -6.1311e-01, -1.5370e+00,  2.9590e-01,  1.2552e+00,  9.3801e-01,\n",
       "           3.4831e+00,  8.3900e-01,  6.5607e-01,  2.3424e+00, -2.5169e+00,\n",
       "           4.9464e-01, -7.9943e-02,  6.2230e-02,  1.0104e+00, -5.2972e-01,\n",
       "           1.1360e+00,  3.8709e-01,  1.1140e+00, -5.9747e-01,  5.8162e-02,\n",
       "           1.9215e+00,  1.0320e-01,  2.1673e+00, -9.3786e-01,  6.2459e-02,\n",
       "           6.6224e-01,  3.5153e-01],\n",
       "         [-1.2884e+00, -5.4220e-01,  4.8975e-02, -1.5991e+00,  1.0390e+00,\n",
       "           3.1534e-01, -7.7721e-01, -4.0024e-01,  1.3719e+00, -6.1061e-01,\n",
       "          -9.7610e-01, -4.0126e-01, -2.7068e-01, -1.2235e+00, -4.0536e-01,\n",
       "          -1.9494e-01,  5.3057e-01, -5.7537e-01,  9.8938e-01,  3.2362e-01,\n",
       "           1.2551e-01, -1.8141e+00, -1.0934e+00, -1.0051e+00, -1.2109e+00,\n",
       "          -1.7673e-01, -9.4396e-01, -1.4489e+00, -7.5010e-01, -1.0736e+00,\n",
       "           9.5358e-01,  7.7746e-01],\n",
       "         [-3.8766e-01,  5.8734e-01, -1.7504e+00, -5.8200e-01,  1.4518e+00,\n",
       "          -2.0279e-01, -5.5114e-01,  1.2416e+00,  6.9454e-01, -3.5066e-01,\n",
       "          -1.2682e+00,  7.0547e-01,  3.9340e-01,  2.4819e-01, -1.4684e-01,\n",
       "          -2.0840e-01,  4.2463e-01, -7.2402e-01,  1.5354e+00, -9.6251e-01,\n",
       "           6.4449e-03,  1.1665e+00,  2.4699e-01,  1.0120e+00,  1.8748e+00,\n",
       "           1.1014e-01,  1.9012e-01,  2.5675e-01,  9.9808e-01,  5.0770e-01,\n",
       "           5.9082e-02,  4.9443e-01]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_with_batch = embeddings.unsqueeze(0)\n",
    "embeddings_with_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "589120eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embeddings_with_batch * math.sqrt(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4492273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.0702e-01, -1.3064e-01,  7.9056e+00,  2.1418e+00, -1.9276e+00,\n",
       "           8.1461e+00, -6.7363e+00,  4.4516e+00, -2.9391e-01,  2.1816e+00,\n",
       "           1.3769e+00,  2.4051e-01,  2.7922e+00, -4.6021e-01, -5.0288e+00,\n",
       "           9.3103e+00,  2.5793e+00,  5.1147e-01,  3.4831e+00,  8.0836e+00,\n",
       "          -1.7043e+00, -4.2113e+00,  2.7276e+00, -8.4000e+00,  3.1645e+00,\n",
       "          -7.0366e-01,  7.8069e-01,  2.7160e+00, -4.9843e+00, -1.1143e+00,\n",
       "           5.2716e-01, -4.3614e+00],\n",
       "         [-1.1749e-01,  5.6558e+00,  4.7827e+00, -7.3460e+00, -1.9481e+00,\n",
       "           9.3914e+00, -3.7743e+00,  9.5835e-01, -5.5529e+00,  1.6014e+00,\n",
       "          -6.0983e+00, -6.5655e-01,  1.0092e+00,  3.1278e+00,  1.0306e+00,\n",
       "           4.3122e+00, -5.6464e+00,  2.0867e+00,  9.6445e-01,  4.6388e+00,\n",
       "          -3.0205e+00, -2.1422e+00,  3.4560e+00, -7.7318e+00, -3.8457e+00,\n",
       "           4.5276e+00,  3.1713e+00,  3.8288e+00, -1.1645e+00, -6.2673e+00,\n",
       "          -7.1486e+00,  4.4954e+00],\n",
       "         [ 5.8672e+00,  3.0677e+00, -9.1124e-01, -4.0230e-01, -1.2402e+00,\n",
       "          -3.4683e+00, -8.6946e+00,  1.6739e+00,  7.1004e+00,  5.3062e+00,\n",
       "           1.9703e+01,  4.7461e+00,  3.7113e+00,  1.3250e+01, -1.4238e+01,\n",
       "           2.7981e+00, -4.5222e-01,  3.5202e-01,  5.7159e+00, -2.9965e+00,\n",
       "           6.4264e+00,  2.1897e+00,  6.3016e+00, -3.3798e+00,  3.2901e-01,\n",
       "           1.0869e+01,  5.8381e-01,  1.2260e+01, -5.3054e+00,  3.5332e-01,\n",
       "           3.7462e+00,  1.9885e+00],\n",
       "         [-7.2884e+00, -3.0671e+00,  2.7704e-01, -9.0459e+00,  5.8774e+00,\n",
       "           1.7838e+00, -4.3965e+00, -2.2641e+00,  7.7606e+00, -3.4541e+00,\n",
       "          -5.5217e+00, -2.2699e+00, -1.5312e+00, -6.9210e+00, -2.2930e+00,\n",
       "          -1.1027e+00,  3.0013e+00, -3.2548e+00,  5.5968e+00,  1.8307e+00,\n",
       "           7.0996e-01, -1.0262e+01, -6.1853e+00, -5.6855e+00, -6.8499e+00,\n",
       "          -9.9976e-01, -5.3399e+00, -8.1962e+00, -4.2432e+00, -6.0730e+00,\n",
       "           5.3942e+00,  4.3980e+00],\n",
       "         [-1.1749e-01,  5.6558e+00,  4.7827e+00, -7.3460e+00, -1.9481e+00,\n",
       "           9.3914e+00, -3.7743e+00,  9.5835e-01, -5.5529e+00,  1.6014e+00,\n",
       "          -6.0983e+00, -6.5655e-01,  1.0092e+00,  3.1278e+00,  1.0306e+00,\n",
       "           4.3122e+00, -5.6464e+00,  2.0867e+00,  9.6445e-01,  4.6388e+00,\n",
       "          -3.0205e+00, -2.1422e+00,  3.4560e+00, -7.7318e+00, -3.8457e+00,\n",
       "           4.5276e+00,  3.1713e+00,  3.8288e+00, -1.1645e+00, -6.2673e+00,\n",
       "          -7.1486e+00,  4.4954e+00],\n",
       "         [-2.2041e+00, -9.9633e-01, -5.6801e-01,  1.3564e-01, -4.0143e+00,\n",
       "           7.0135e-01, -8.8295e+00, -3.5595e+00,  9.7333e-01,  1.0046e+01,\n",
       "          -3.2507e+00,  1.9231e+00, -6.7554e-02, -3.0345e+00,  9.4151e-01,\n",
       "           1.8546e+00, -5.7513e+00, -2.6884e+00, -4.3490e+00,  5.6392e+00,\n",
       "           3.9796e+00,  1.7166e+00,  3.1185e+00, -8.9827e+00, -8.1657e+00,\n",
       "           4.7004e+00, -3.3236e+00,  1.5598e+00,  8.9154e-02, -7.4956e+00,\n",
       "           1.6443e+00, -7.7154e+00],\n",
       "         [-1.5965e+00,  2.4524e+00, -5.4603e+00, -1.4345e+00,  1.1983e+00,\n",
       "          -4.5324e+00, -4.6956e+00, -8.9716e+00,  4.9988e+00, -4.2359e+00,\n",
       "           1.7136e-02,  5.6070e+00, -2.0842e+00, -7.5363e-01,  9.9318e+00,\n",
       "           3.1201e+00, -3.1610e+00, -7.3840e+00,  3.1671e-01,  1.2286e+01,\n",
       "           6.5001e+00,  7.2140e-01, -7.7035e+00, -2.3149e+00, -1.7894e+00,\n",
       "           3.2822e-01,  1.0012e+01,  6.4022e-01, -1.0164e+00, -1.9286e+00,\n",
       "           1.3217e+00, -1.7226e+01],\n",
       "         [-8.2881e+00, -4.4304e-01, -2.8360e+00,  1.0933e+01,  1.4000e+00,\n",
       "           8.2856e+00, -4.8831e+00, -8.7692e-01,  4.2535e+00, -6.6562e+00,\n",
       "           5.0484e+00, -4.5746e+00,  2.1963e+00, -6.7177e-01, -6.3992e+00,\n",
       "           4.9277e+00, -7.9243e-01, -1.5745e-01,  1.4685e+01, -5.1072e-01,\n",
       "           1.3674e-01, -3.7976e+00, -7.4256e-01, -6.5236e-01,  2.6248e+00,\n",
       "          -4.4880e+00, -7.9691e+00, -3.5328e+00,  2.0545e+00, -4.8287e+00,\n",
       "          -3.1244e-01,  3.4719e+00],\n",
       "         [ 5.8672e+00,  3.0677e+00, -9.1124e-01, -4.0230e-01, -1.2402e+00,\n",
       "          -3.4683e+00, -8.6946e+00,  1.6739e+00,  7.1004e+00,  5.3062e+00,\n",
       "           1.9703e+01,  4.7461e+00,  3.7113e+00,  1.3250e+01, -1.4238e+01,\n",
       "           2.7981e+00, -4.5222e-01,  3.5202e-01,  5.7159e+00, -2.9965e+00,\n",
       "           6.4264e+00,  2.1897e+00,  6.3016e+00, -3.3798e+00,  3.2901e-01,\n",
       "           1.0869e+01,  5.8381e-01,  1.2260e+01, -5.3054e+00,  3.5332e-01,\n",
       "           3.7462e+00,  1.9885e+00],\n",
       "         [-7.2884e+00, -3.0671e+00,  2.7704e-01, -9.0459e+00,  5.8774e+00,\n",
       "           1.7838e+00, -4.3965e+00, -2.2641e+00,  7.7606e+00, -3.4541e+00,\n",
       "          -5.5217e+00, -2.2699e+00, -1.5312e+00, -6.9210e+00, -2.2930e+00,\n",
       "          -1.1027e+00,  3.0013e+00, -3.2548e+00,  5.5968e+00,  1.8307e+00,\n",
       "           7.0996e-01, -1.0262e+01, -6.1853e+00, -5.6855e+00, -6.8499e+00,\n",
       "          -9.9976e-01, -5.3399e+00, -8.1962e+00, -4.2432e+00, -6.0730e+00,\n",
       "           5.3942e+00,  4.3980e+00],\n",
       "         [-8.2881e+00, -4.4304e-01, -2.8360e+00,  1.0933e+01,  1.4000e+00,\n",
       "           8.2856e+00, -4.8831e+00, -8.7692e-01,  4.2535e+00, -6.6562e+00,\n",
       "           5.0484e+00, -4.5746e+00,  2.1963e+00, -6.7177e-01, -6.3992e+00,\n",
       "           4.9277e+00, -7.9243e-01, -1.5745e-01,  1.4685e+01, -5.1072e-01,\n",
       "           1.3674e-01, -3.7976e+00, -7.4256e-01, -6.5236e-01,  2.6248e+00,\n",
       "          -4.4880e+00, -7.9691e+00, -3.5328e+00,  2.0545e+00, -4.8287e+00,\n",
       "          -3.1244e-01,  3.4719e+00],\n",
       "         [ 5.0457e+00, -5.4762e+00,  3.5624e+00,  5.3770e-01, -7.1968e+00,\n",
       "           2.9076e+00, -1.6085e+01,  1.9294e+00,  5.0462e+00, -5.0888e-01,\n",
       "           7.0115e+00, -1.5016e+00, -1.0090e+01, -2.4565e-01,  3.6845e+00,\n",
       "           5.6285e+00, -1.4741e+00, -3.5775e+00, -3.7846e+00,  3.8870e+00,\n",
       "          -2.1536e+00, -3.6496e+00, -6.7659e-02,  3.2174e+00,  6.4344e-02,\n",
       "           1.0744e+01, -3.7790e+00,  1.2855e+00,  4.6916e-01, -5.6903e+00,\n",
       "          -8.7391e+00,  3.6921e+00],\n",
       "         [-2.1929e+00,  3.3225e+00, -9.9016e+00, -3.2923e+00,  8.2126e+00,\n",
       "          -1.1472e+00, -3.1177e+00,  7.0237e+00,  3.9289e+00, -1.9836e+00,\n",
       "          -7.1741e+00,  3.9907e+00,  2.2254e+00,  1.4040e+00, -8.3067e-01,\n",
       "          -1.1789e+00,  2.4020e+00, -4.0957e+00,  8.6854e+00, -5.4448e+00,\n",
       "           3.6458e-02,  6.5987e+00,  1.3972e+00,  5.7245e+00,  1.0605e+01,\n",
       "           6.2306e-01,  1.0755e+00,  1.4524e+00,  5.6460e+00,  2.8720e+00,\n",
       "           3.3422e-01,  2.7969e+00],\n",
       "         [ 2.5889e+00,  2.0029e+00,  1.5506e+00, -4.9208e+00, -4.1769e+00,\n",
       "          -5.5631e+00, -1.2405e+00,  2.6993e+00,  1.1701e+00,  2.5901e-01,\n",
       "           3.4293e+00, -3.2958e+00, -9.9183e-01, -7.1271e+00,  8.3856e+00,\n",
       "          -2.7913e+00,  2.5625e+00, -7.6094e+00,  2.6808e-01, -1.8332e+00,\n",
       "           4.4354e+00,  2.4341e+00,  2.4782e+00,  2.2613e+00, -4.8529e+00,\n",
       "          -4.4448e+00, -2.9068e+00, -5.7744e+00, -3.8357e+00,  4.8694e+00,\n",
       "           3.6156e-01, -1.0539e+01],\n",
       "         [ 2.5521e+00, -2.1361e-01, -1.1036e+01, -1.0851e+01,  1.9988e+00,\n",
       "          -5.3793e+00, -1.3619e+00,  3.5130e+00,  6.7236e+00, -1.8205e+00,\n",
       "           2.2491e-01, -5.2515e+00, -3.0744e+00, -5.5159e+00,  1.3230e+00,\n",
       "          -5.3728e+00, -7.0871e+00,  6.6137e+00,  1.0690e+01,  8.9889e+00,\n",
       "          -8.2374e+00,  4.0705e+00, -1.3353e+01, -2.3959e+00,  6.9931e+00,\n",
       "           4.7873e+00,  7.9466e-01,  1.8186e+00,  6.9594e+00, -5.2709e+00,\n",
       "           6.3669e+00,  1.2035e+00],\n",
       "         [-8.2881e+00, -4.4304e-01, -2.8360e+00,  1.0933e+01,  1.4000e+00,\n",
       "           8.2856e+00, -4.8831e+00, -8.7692e-01,  4.2535e+00, -6.6562e+00,\n",
       "           5.0484e+00, -4.5746e+00,  2.1963e+00, -6.7177e-01, -6.3992e+00,\n",
       "           4.9277e+00, -7.9243e-01, -1.5745e-01,  1.4685e+01, -5.1072e-01,\n",
       "           1.3674e-01, -3.7976e+00, -7.4256e-01, -6.5236e-01,  2.6248e+00,\n",
       "          -4.4880e+00, -7.9691e+00, -3.5328e+00,  2.0545e+00, -4.8287e+00,\n",
       "          -3.1244e-01,  3.4719e+00],\n",
       "         [-2.5518e+00, -5.5745e+00, -3.5359e-01, -3.5725e+00,  5.9670e-01,\n",
       "           1.4827e+00, -3.9591e+00,  2.3907e+00, -5.4286e+00,  6.8240e-01,\n",
       "           2.3061e-01,  2.6037e+00, -8.6746e+00,  2.9480e+00,  3.0066e+00,\n",
       "          -1.5506e+01, -4.0930e+00,  2.9734e+00,  4.1693e+00,  1.5075e+00,\n",
       "          -3.1048e+00,  4.4320e+00, -9.2540e-01,  9.1450e+00, -1.3957e+00,\n",
       "          -3.2340e+00, -3.6050e+00,  3.7356e+00, -4.5678e+00,  4.4747e+00,\n",
       "           3.7588e+00,  3.6114e+00],\n",
       "         [ 5.8672e+00,  3.0677e+00, -9.1124e-01, -4.0230e-01, -1.2402e+00,\n",
       "          -3.4683e+00, -8.6946e+00,  1.6739e+00,  7.1004e+00,  5.3062e+00,\n",
       "           1.9703e+01,  4.7461e+00,  3.7113e+00,  1.3250e+01, -1.4238e+01,\n",
       "           2.7981e+00, -4.5222e-01,  3.5202e-01,  5.7159e+00, -2.9965e+00,\n",
       "           6.4264e+00,  2.1897e+00,  6.3016e+00, -3.3798e+00,  3.2901e-01,\n",
       "           1.0869e+01,  5.8381e-01,  1.2260e+01, -5.3054e+00,  3.5332e-01,\n",
       "           3.7462e+00,  1.9885e+00],\n",
       "         [-7.2884e+00, -3.0671e+00,  2.7704e-01, -9.0459e+00,  5.8774e+00,\n",
       "           1.7838e+00, -4.3965e+00, -2.2641e+00,  7.7606e+00, -3.4541e+00,\n",
       "          -5.5217e+00, -2.2699e+00, -1.5312e+00, -6.9210e+00, -2.2930e+00,\n",
       "          -1.1027e+00,  3.0013e+00, -3.2548e+00,  5.5968e+00,  1.8307e+00,\n",
       "           7.0996e-01, -1.0262e+01, -6.1853e+00, -5.6855e+00, -6.8499e+00,\n",
       "          -9.9976e-01, -5.3399e+00, -8.1962e+00, -4.2432e+00, -6.0730e+00,\n",
       "           5.3942e+00,  4.3980e+00],\n",
       "         [-2.1929e+00,  3.3225e+00, -9.9016e+00, -3.2923e+00,  8.2126e+00,\n",
       "          -1.1472e+00, -3.1177e+00,  7.0237e+00,  3.9289e+00, -1.9836e+00,\n",
       "          -7.1741e+00,  3.9907e+00,  2.2254e+00,  1.4040e+00, -8.3067e-01,\n",
       "          -1.1789e+00,  2.4020e+00, -4.0957e+00,  8.6854e+00, -5.4448e+00,\n",
       "           3.6458e-02,  6.5987e+00,  1.3972e+00,  5.7245e+00,  1.0605e+01,\n",
       "           6.2306e-01,  1.0755e+00,  1.4524e+00,  5.6460e+00,  2.8720e+00,\n",
       "           3.3422e-01,  2.7969e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9791a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pos_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dfe3d7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 32])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Your Configuration ---\n",
    "EMBEDDING_DIM = 32\n",
    "vocab_size = 81\n",
    "MAX_SEQUENCE_LENGTH = 50 # Example: max number of tokens in a sentence\n",
    "\n",
    "# --- The Layers ---\n",
    "# 1. Your existing embedding layer\n",
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=EMBEDDING_DIM)\n",
    "\n",
    "# 2. The new positional encoding layer\n",
    "pos_encoder = PositionalEncoding(d_model=EMBEDDING_DIM, max_len=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# --- The Forward Pass ---\n",
    "# Create a dummy input (Batch Size = 2, Sequence Length = 10)\n",
    "input_indices = torch.randint(0, vocab_size, (2, 10))\n",
    "\n",
    "# Step 1: Get Embeddings [2, 10, 32]\n",
    "# It is common practice to scale embeddings by sqrt(d_model) before adding PE\n",
    "x = embedding_layer(input_indices) * math.sqrt(EMBEDDING_DIM)\n",
    "\n",
    "# Step 2: Add Positional Encoding\n",
    "x = pos_encoder(x)\n",
    "\n",
    "print(f\"Output shape: {x.shape}\") \n",
    "# Output: torch.Size([2, 10, 32])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
