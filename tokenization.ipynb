{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eae097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeb16c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\1. Adi parva.txt | Length: 1334206\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\2. Sabha parva.txt | Length: 441967\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\3. VANA PARVA.txt | Length: 1864194\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\4. VIRATA PARVA.txt | Length: 356183\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\5. UDYOGA PARVA.txt | Length: 1097364\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\6. BHISHMA PARVA.txt | Length: 882776\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\7.DRONA PARVA.txt | Length: 1465367\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\8.Karna-parva.txt | Length: 817407\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\9. Shalya-parva.txt | Length: 542317\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\10.Sauptika-parva.txt | Length: 124459\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\11.Stri-parva.txt | Length: 127084\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\12.SANTI PARVA.txt | Length: 2663816\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\13.ANUSASANA PARVA.txt | Length: 1583610\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\14.ASWAMEDHA PARVA.txt | Length: 477607\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\15.ASRAMAVASIKA PARVA.txt | Length: 178497\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\16.Mausala-parva.txt | Length: 47109\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\17.Mahaprasthanika-parva.txt | Length: 17810\n",
      "Path: C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\\18.Svargarohanika-parva.txt | Length: 50769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from natsort import natsorted\n",
    "folder_path = r\"C:\\My learnings\\Transformer architecture\\Building-llm\\Mahabharatha Datasets\"\n",
    "files = natsorted(os.listdir(folder_path))\n",
    "corpus = ''\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()  # Read ONCE\n",
    "        print(f\"Path: {file_path} | Length: {len(content)}\")\n",
    "        corpus += content + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc93825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14072560"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5b29e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vocab size: 81\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(corpus))\n",
    "print(sorted(vocab))\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af4efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
